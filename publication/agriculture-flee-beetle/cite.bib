@article{BERECIARTUAPEREZ202418,
title = {Estimation of flea beetle damage in the field using a multistage deep learning-based solution},
journal = {Artificial Intelligence in Agriculture},
volume = {13},
pages = {18-31},
year = {2024},
issn = {2589-7217},
doi = {https://doi.org/10.1016/j.aiia.2024.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2589721724000199},
author = {Arantza Bereciartua-Pérez and María Monzón and Daniel Múgica and Greta {De Both} and Jeroen Baert and Brittany Hedges and Nicole Fox and Jone Echazarra and Ramón Navarra-Mestre},
keywords = {Convolutional neural networks, Deep learning, Plant phenotyping, Damage estimation, Plant crop detection and identification},
abstract = {Estimation of damage in plants is a key issue for crop protection. Currently, experts in the field manually assess the plots. This is a time-consuming task that can be automated thanks to the latest technology in computer vision (CV). The use of image-based systems and recently deep learning-based systems have provided good results in several agricultural applications. These image-based applications outperform expert evaluation in controlled environments, and now they are being progressively included in non-controlled field applications. A novel solution based on deep learning techniques in combination with image processing methods is proposed to tackle the estimate of plant damage in the field. The proposed solution is a two-stage algorithm. In a first stage, the single plants in the plots are detected by an object detection YOLO based model. Then a regression model is applied to estimate the damage of each individual plant. The solution has been developed and validated in oilseed rape plants to estimate the damage caused by flea beetle. The crop detection model achieves a mean precision average of 91% with a mAP@0.50 of 0.99 and a mAP@0.95 of 0.91 for oilseed rape specifically. The regression model to estimate up to 60% of damage degree in single plants achieves a MAE of 7.11, and R2 of 0.46 in comparison with manual evaluations done plant by plant by experts. Models are deployed in a docker, and with a REST API communication protocol they can be inferred directly for images acquired in the field from a mobile device.}
}