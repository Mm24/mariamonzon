<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research | Maria Monzon</title>
    <link>https://mariamonzon.com/tag/research/</link>
      <atom:link href="https://mariamonzon.com/tag/research/index.xml" rel="self" type="application/rss+xml" />
    <description>Research</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 May 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://mariamonzon.com/media/icon_huaad826f52d8c51d03abf0418cbb027d5_448596_512x512_fill_lanczos_center_3.png</url>
      <title>Research</title>
      <link>https://mariamonzon.com/tag/research/</link>
    </image>
    
    <item>
      <title>Deep Learning based reach-and-grasp EEG decoder</title>
      <link>https://mariamonzon.com/project/eeg-grasp-decoder/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      <guid>https://mariamonzon.com/project/eeg-grasp-decoder/</guid>
      <description>&lt;p&gt;The most common technique to measure the brain noninvasively is the electroencephalogram (EEG), due to its ease of use and cost/performance trade-off.&lt;/p&gt;
&lt;p&gt;An EEG is a non-invasive technique that consists of placing electrodes on the head to monitor the electrical activity produced when neurons fire. The EEG records and measures electrical signals of the human brain from multiple cortical areas. Therefore, EEG monitoring allows us to quantify different types of brain waves, also known as neural oscillations. Some of the best-known and most-advertised applications of EEG-based neurotechnologies are brain-control of different types of devices&lt;/p&gt;
&lt;p&gt;Despite the high number of degrees of freedom of the human hand, most actions of daily life can be executed incorporating only palmar, pincer and lateral grasp. In this study we attempt to discriminate these three different executed reach-and-grasp actions utilizing their EEG neural correlates.&lt;/p&gt;
&lt;p&gt;In a cue-guided experiment (see Figure 1), 15 healthy individuals were asked to perform reach-and-grasp actions using daily life objects. We recorded
72 trials for each reach-and-grasp condition and from a no-movement condition. In an oﬄine multiclass classiﬁcation scenario (10 x 5 crossvalidation),
which incorporated not only all reach-and-grasp actions but also the no-movement condition, we used a window of 1000 ms for extracting time domain
features.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fully automatic extraction of mitral valve annulus motion parameters on long axis CINE CMR using deep learning</title>
      <link>https://mariamonzon.com/project/cardiac-parameter-extraction/</link>
      <pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://mariamonzon.com/project/cardiac-parameter-extraction/</guid>
      <description>&lt;p&gt;Diastolic dysfunction is an important cause of cardiac insuf-
ficiency, defined as a malfunctioning filling of the heart during diastole.
The analysis of mitral valve motion is known to be relevant in the diagno-
sis of cardiac dysfunction. Cardiac motion parameters can be extracted
from Cardiac Magnetic Resonance (CMR) images. However, in clinical
setting valve motion modeling usually needs a manual intervention to lo-
calize the valvular plane. We propose two chained Convolutional Neural
Networks (CNN) for automatic tracking of mitral valve-annulus land-
marks on time-resolved 2-chamber and 4-chamber CMR images. 
The first CNN is trained to detect the region of interest and the second to
track the landmarks along the cardiac cycle. The presented deep learn-
ing system has high accuracy in terms of temporal landmark tracking
and motion assessment. Furthermore, we successfully extracted several
motion-related parameters thereby overcoming time-consuming annota-
tion and allowing statistical analysis over a large number of datasets.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Assessment of cardiac valve motion on time-resolved MRI images using deep learning</title>
      <link>https://mariamonzon.com/project/valve-cardiac-motion-assesment/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://mariamonzon.com/project/valve-cardiac-motion-assesment/</guid>
      <description>&lt;p&gt;The presented work aimed to develop a novel method for the task of valve motion
assessment for prospective slice tracking in CMR temporal image (CINE) acquisition. 
The objective this thesis &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; was to evaluate deep learning-based landmarks tracking methods to extract the
motion of the mitral valves throughout the cardiac cycle on time-resolved CMR four-chamber-
view (4CHV) images. The fully automated CNN based algorithm would improve the current slice following acquisition workflow, which needs from manual user intervention. 
The automatic imaging slice tracking will enable a more precise morphology and flow estimation, potentially
improving the diagnosis of diastolic dysfunction. During this project, an automatic deep learning algorithm using landmark detection was developed.&lt;/p&gt;
&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Cardio-vascular diseases remain the leading cause of death worldwide [1]. In particular, diastolic dys-
function is an important cause of cardiac insufficiency, heart failure, potentially leading to premature
cardiovascular death if not diagnosed and treated for at an early disease stage. Left ventricular dias-
tolic dysfunction is estimated to affect from 27% to 43% in middle-aged adults [2] and its prevalence
increases with age.&lt;/p&gt;
&lt;p&gt;Diastolic dysfunction is defined as a malfunctioning filling of the heart during diastole [3]. Its diag-
nostic remains challenging as not only structural but functional abnormalities need to be evaluated [4].
Several non-invasive imaging techniques have been used for assessing diastolic dysfunction.
Typically, intra-cardiac haemodynamics are measured using Doppler echocardiography. The peak
velocities during early diastolic filling (E wave) and atrial contraction (A wave) are measured, and their
ratio is calculated [5]. The Doppler flow measures are influenced by multiple factors including age,
valve heart diseases, heart rate. Therefore, no single parameter is determinant enough to asses diastolic
dysfunction [6].&lt;/p&gt;
&lt;p&gt;Magnetic Resonance Imaging (MRI) is a noninvasive technique, well suited for disease diagnosis
and monitoring due to its high spatial and temporal resolution and excellent soft-tissue contrast. In-
deed, Cardiac Magnetic Resonance (CMR) provides information about heart structure and function,
particularly in soft tissue characterization without the need of any contrast agent. Furthermore, CMR
is useful for characterizing the anatomic valve morphology and cine images allows to visualize the valve
throughout the cardiac cycle [7, 8]. Indeed, CMR allows assessment of blood flow using phase-contrast
MRI (PC-MRI) [9].&lt;/p&gt;
&lt;p&gt;As the valves move during a cardiac cycle, the acquisition of a fixed 2D slice will not allow the
accurate time-resolved visualization of the valve and quantification of the blood flow: The valve moves
into and out of the MRI slice so cannot be seen on each cardiac phase, therefore, the quantified flow
through the valve is not correct. Despite the importance of correct valve flow assessment, time resolved
CMR is yet usually performed at fixed slice positions throughout the cardiac cycle Kozerke et al. [10]
introduced the prospective slice tracking concept. If the valve motion is known prior to the examina-
tion, the slice position can be updated for each cardiac phase. As this approach however requires a
dedicated pre-scan including an image-based algorithm to quantify the valve motion, very few related
work can be found applying this technique in a clinical setting.&lt;/p&gt;
&lt;p&gt;The recent development of deep learning has led to significant improvements in medical image
analysis [11]. The prominent algorithms for feature tracking include deep learning systems based on
convolutional neural network architectures. Specifically, for valve-tracking, a deep learning feature
tracking algorithm for automatic slice-tracking can be developed, overcoming many limitations of the
current valve-tracking techniques. The imaging slice tracking will enable a more precise morphology
and flow estimation, potentially improving the diagnosis of diastolic dysfunction.&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;The dataset is composed of Cardiac Magnetic Resonance Imaging 4CHV CINE series from 87
patients extracted from the Cardiac Atlas Project [Fon11]. The imaging protocol included CINE
images acquired in long-axis planes, but for our work we only selected the 4CHV long axis view.
The sequence of 4CHV CINE CMR are acquired on multiple 1.5T MRI scanners from
different vendors (Philips, Siemens, GE). The mean pixel spacing of all selected datasets
is 1.49 + 0.28 mm/pixel. Additionally the annotated dataset contains anatomical landmarks, i.e.
the mitral valve position at each temporal aframe nnotated by an experienced analyst. 
As a preprocessing step, the CINE series were interpolated into a fixed and temporal resolution and
horizontally flipped to have all the images oriented with the apex of the heart upwards. Finally,the
input images intensity were normalized to 0-1 range values. After cleaning the data, the dataset
contain 87 series that are split into 70% for training and the rest 30% equally between test and
validation. To increase the variability of the dataset, online data augmentation was performed
when training the network in forms of shift, center cropping, rotation, Guassian noise addition,
contrast enhancement and Gaussian blurring.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://mariamonzon.com/images/valve-cardiac-motion-assesment/data-exampleslice.png&#34; alt=&#34;data-visualization&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;system-overview&#34;&gt;System Overview&lt;/h2&gt;
&lt;p&gt;The motion assesment system is composed of four main stages. The preprocessed CINE dataset are forwarded as input to a convolutional based neural network (CNN).
The final proposed system comprises two chained CNNs based on heatmap regression approach: Localization Network + Landmark Detection Network. The task of the localization CNN model is to detect the landmarks only in the first temporal frame of the full 4CHV CINE series. The complete system is designed to regress the mitral valve-annulus landmarks for each time-frame points. 
Finally, the valvular plane motion can be derived from the two predicted landmark distance. The predicted temporal coordinates are translated into mm-space.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://mariamonzon.com/images/valve-cardiac-motion-assesment/system-overview.png&#34; alt=&#34;results-visualization&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;Evaluated heatmap based regression approach for landmark detection yields to a superior performance than direct coordinate regression.Especially, the motion is better modeled by the two-stages architectures than with 3-D instead
of single network. The proposed system showed an accurate match between expert-annotated
and automatically detected landmarks for each time-frame. An example results of the model is shown in the below figure:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://mariamonzon.com/images/valve-cardiac-motion-assesment/results-motion-curves.png&#34; alt=&#34;results-visualization&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

The complete system has an accuracy of 1.66+- 0.75 mm. The roughness metric has a similar value as the ground truth annotations R = 0.085 +- 0.045 and the total slope variation value is TVslope = 0.53 +- 0.28.&lt;/p&gt;
&lt;p&gt;Our proposed method allows landmark localization with sub-pixel accuracy. Experiments
show that our approach is able to correctly locate the landmark which can assess the prospective
slice tracking acquisition method. The results of this work can be summarized as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CNNs can be used to develop a time-resolved landmark tracking application without the
need of any user interaction.&lt;/li&gt;
&lt;li&gt;Heart landmark detection with the deep learning results can be improved by means of regressing heatmaps.&lt;/li&gt;
&lt;li&gt;The proposed two-stages method further allows a more accurate localization.&lt;/li&gt;
&lt;li&gt;A post-processing step with the non-linear least square fitting is able to refine the landmark
location. The additional step outputs subpixel maxima and therefore predicts a smooth
motion.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion-and-outlook&#34;&gt;Conclusion and Outlook&lt;/h2&gt;
&lt;p&gt;The proposed system enables the valve tracking detection over time and therefore smooth valve motion assessment. 
Future work would focus on extension on the algorithm to 2CHV valve landmark detection. Evaluation with more test data
and further refinement of the network. An integration of a single CNN could be convenient for faster inference time. Finally, when the validity of the method is proved , the scanner integration would be the next step.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] World Health Organization, World Health Statistics 2019: Monitoring Health for the SDGs. Geneva, Switzerland:
World Health Organization, 2019.&lt;/p&gt;
&lt;p&gt;[2] M. Nayor, L. L. Cooper, D. M. Enserro, V. Xanthakis, M. G. Larson, E. J. Benjamin, J. Aragam, G. F. Mitchell, and
R. S. Vasan, “Left ventricular diastolic dysfunction in the community: Impact of diagnostic criteria on the burden,
correlates, and prognosis,” Journal of the American Heart Association, vol. 7, no. 11, 2018.&lt;/p&gt;
&lt;p&gt;[3] A. Kossaify and M. Nasr, “Diastolic dysfunction and the new recommendations for echocardiographic assessment
of left ventricular diastolic function: Summary of guidelines and novelties in diagnosis and grading,” Journal of
Diagnostic Medical Sonography, vol. 35, no. 4, pp. 317–325, 2019.&lt;/p&gt;
&lt;p&gt;[4] C. Gutierrez and D. G. Blanchard, “Diastolic heart failure: Challenges of diagnosis and treatment,” American Family
Physician, vol. 69, no. 11, pp. 2609–2616, 2004.&lt;/p&gt;
&lt;p&gt;[5] C. Dugo, M. Rigolli, A. Rossi, and G. A. Whalley, “Assessment and impact of diastolic function by echocardiography
in elderly patients.,” Journal of geriatric cardiology : JGC, vol. 13, no. 3, pp. 252–25260, 2016.&lt;/p&gt;
&lt;p&gt;[6] S. F. Nagueh, O. A. Smiseth, C. P. Appleton, I. Byrd, Benjamin F., H. Dokainish, T. Edvardsen, F. A. Flachskampf,
T. C. Gillebert, A. L. Klein, P. Lancellotti, P. Marino, J. K. Oh, B. Alexandru Popescu, and Waggoner, “Recom-
mendations for the Evaluation of Left Ventricular Diastolic Function by Echocardiography: An Update from the
American Society of Echocardiography and the European Association of Cardiovascular Imaging,” European Heart
Journal - Cardiovascular Imaging, vol. 17, pp. 1321–1360, 07 2016.&lt;/p&gt;
&lt;p&gt;[7] S. Shah, E. D. Chryssos, and H. Parker, “Magnetic resonance imaging: a wealth of cardiovascular information.,” The
Ochsner journal, vol. 9, no. 4, pp. 266–77, 2009.&lt;/p&gt;
&lt;p&gt;[8] K. Maganti, V. H. Rigolin, M. E. Sarano, and R. O. Bonow, “Valvular heart disease: diagnosis and management.,”
Mayo Clinic proceedings, vol. 85, pp. 483–500, may 2010.&lt;/p&gt;
&lt;p&gt;[9] P. Waheed, A. K. Naveed, and F. Farooq, “Cardiovascular magnetic resonance physics for clinicians: part I,” Journal
of the College of Physicians and Surgeons Pakistan, vol. 19, no. 4, pp. 207–210, 2009.&lt;/p&gt;
&lt;p&gt;[10] S. Kozerke, J. Schwitter, E. M. Pedersen, and P. Boesiger, “Aortic and mitral regurgitation: Quantification using
moving slice velocity mapping,” Journal of Magnetic Resonance Imaging, vol. 14, no. 2, pp. 106–112, 2001.&lt;/p&gt;
&lt;p&gt;[11] A. Maier, C. Syben, T. Lasser, and C. Riess, “A gentle introduction to deep learning in medical image processing,”
Zeitschrift f ̈ur Medizinische Physik, vol. 29, no. 2, pp. 86 – 101, 2019.&lt;/p&gt;
&lt;p&gt;[12] S. S. Yoon, E. Hoppe, M. Schmidt, C. Forman, P. Sharma, C. Tilmanns, A. Maier, and J. Wetzl, “Automatic Cardiac
Resting Phase Detection for Static Cardiac Imaging Using Deep Neural Networks,” in Proceedings of the Joint
Annual Meeting ISMRM-ESMRMB (27th Annual Meeting &amp;amp; Exhibition) (I. S. for Magnetic Resonance in Medicine,
ed.), 2019.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;All the algorithims will be developed in python using the Pytorch deep learning framework. The data
for training, validation and testing will be provided by Siemens Healthineers.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Myocardial Pathology Segmentation Combining Multi-Sequence Cardiac Magnetic Resonance Images</title>
      <link>https://mariamonzon.com/project/myocardial-scar-segmentation/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://mariamonzon.com/project/myocardial-scar-segmentation/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Accurate segmentation of myocardial pathological tissue from cardiac magnetic resonance images (CMR), such as scar tissue and edema, f is crutial to the assessment of the severity of myocardial infarction (MI).
CMRis the gold standar to provide anatomical and functional information of heart. Specifically, late gadolinium enhancement (LGE) CMR sequence which is used to diagnosis MI, the T2-weighted CMR which resembles ischemic regions, and the balanced- Steady State Free Precession (bSSFP) cine sequence which captures cardiac motions . Combining these multi-sequence CMR data could provide reliable information regarding to the pathological as well as morphological information of the myocardium &lt;a href=&#34;http://www.sdspeople.fudan.edu.cn/zhuangxiahai/0/myops20/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[1]&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;The input dataset  contains 45 cases of multi-sequence CMR from Myops2020 challenge &lt;a href=&#34;http://www.sdspeople.fudan.edu.cn/zhuangxiahai/0/myops20/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[1]&lt;/a&gt;









. Each case refers to a patient with three sequence CMR, i.e., LGE, T2 and bSSFP CMR. All these clinical data have got institutional ethic approval and have been anonymized.
The “masks” folder contains 45 cases of multi-sequence CMR, where each mask represents the segmentation map of the the corresponding CMR Slice image:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Label 1: normal myocardium&lt;/li&gt;
&lt;li&gt;Label 2: edema&lt;/li&gt;
&lt;li&gt;Label 3: scar&lt;/li&gt;
&lt;li&gt;Label 0: Background&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://mariamonzon.com/images/myops-scar-segmentation/example.png&#34; alt=&#34;example&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The proposed approach involves a two-staged network. First a heatmap-based regression architecture was train to detect a small ROI and locate the myocardium, based on , in order to reduce task complexity. Sequentially a a U-Net based neural network was train to perform  multi-modal pathological region segmentation.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://mariamonzon.com/images/myops-scar-segmentation/108_T2_1.png&#34; alt=&#34;pathology-example&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Adaptive Frame Rate for Egocentric Video</title>
      <link>https://mariamonzon.com/project/adaptive-frame-sampling/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://mariamonzon.com/project/adaptive-frame-sampling/</guid>
      <description>&lt;p&gt;The goal of the project seminar is to implement an adaptive sampling strategy to dynamically
tune the sampling rate of a wearable egocentric camera. The sampling rate will be tuned
based on context measure, i.e., a measure of motion, extracted from the frames.&lt;/p&gt;
&lt;p&gt;The increasing development new media and data acquisition techniques have lead to new
innovative video recording set ups. A clear example of that is the egocentric video, where
a camera on head or on the chest approximates the visual field of the camera wearer.
This new camera setting offers a valuable perspective to understand user&amp;rsquo;s activities and
their context. In this case, the wearable head-mounted egocentric camera set up pursued
a dietary event spotting in a free living condition.&lt;/p&gt;
&lt;p&gt;A main feature of free-living data is a long recording duration. However, this kind of
camera often acquire irrelevant data for the analysis task.
In this work we introduce an adaptive sampling strategy to dynamically tune the sam-
pling rate of a wearable egocentric camera. The adaptive sampling rate is based on a
context measure. It is a motion measure, indicative if the recorded activity might be of
our interest.&lt;/p&gt;
&lt;p&gt;To evaluate the sampling strategy we implemented a computational simulation of resource consumption in terms of energy consumption and memory storage. For this purpose, I designed an analytical energy and memory model, a
nd base our analysis on data extracted from datasheets. Our energy and memory model considers
both sensing components, i.e., the cmos sensor, and processing, i.e., the microcontroller
to process the deep neural network.&lt;/p&gt;
&lt;p&gt;The clear advantage of an adaptive frame rate is saving energy as the camera will not be
acquiring data continuously. 
Benefits from our method will be longer recording sessions, smaller battery employment or smaller
storage space usage. This would help to overcome the limitations of the video recording,
in terms of power consumption, while maintaining acceptable performance. 
Furthermore, less data acquisition will also mean an energy saving in processing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ECG-based algorithm for Annotation of Resuscitation Episode</title>
      <link>https://mariamonzon.com/project/ecg-annotation-svm-classifier/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://mariamonzon.com/project/ecg-annotation-svm-classifier/</guid>
      <description>&lt;p&gt;Out-of hospital cardiac arrest (OHCA) is one of the major causes of death in developed countries. Resuscitation guidelines recommend different treatments depending on the heart rhythm of the patient. The objective of this work is to develop a machine learning algorithm based on the ECG signal to automatically label heart rhythms in resuscitation episodes, a key tool for the retrospectively evaluation and improvement of the quality treatment. This work would help to systematise the annotation of databases since manual annotation of rhythms is a time-consuming task which can be an obstacle for handling large data sets.&lt;/p&gt;
&lt;p&gt;The starting point of this project was a database composed of 1631 intervals of 3 seconds taken from a larger database containing OHCA 298 episodes. To review the ECG segments, a graphical interface (GUI) was developed which allows the display of the ECGs classified by the type of arrhythmia: 
asystole (AS), ventricular tachycardia (VT) that degenerates into ventricular fibrillation (VF), pulseless electrical activity (PEA) pulse generating rhythms (PR).&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://mariamonzon.com/images/egc-svm-annotation/GUI-visualization.png&#34; alt=&#34;GUI-example-visualization&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The database has been processed using a machine learning algorithm and the results obtained using cross-validation. Two classifiers have been developed selecting five features of the ECG, first to identify AS, and then to discriminate organised rhythms (PR and PEA) from ventricular arrhythmias (VT and VF).&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://mariamonzon.com/images/egc-svm-annotation/ECG-classification-Example.png&#34; alt=&#34;ECG-Visualization&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;These algorithms have been combined to create a three class rhythm classification algorithm. The total accuracy of the final algorithm was 90.9%. A precise algorithm was obtained for the classification of OHCA rhythm into: AS, organised,  and  shockable  rhythms.  This  algorithm  can  be  implemented  to  analyse resuscitation episodes using 3 seconds ECG segments, and could be integrated into new methods for retrospective analysis of OHCA.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://mariamonzon.com/images/egc-svm-annotation/SVM-classification-results.png&#34; alt=&#34;ECG-Visualization&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The results show that it is possible to automatically  interpret  resuscitation  cardiac  rhythm. These types of algorithms can be very useful since they allow an efficient rhythm classification with a minimum level of expert clinician supervision&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
